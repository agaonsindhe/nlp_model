{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Grammar Correction Project - Data Exploration & Testing\n\n", "This notebook is designed to:\n\n", "1. **Explore the dataset**: Load and inspect the dataset to understand its structure.\n", "2. **Test preprocessing**: Tokenize sentences and verify input-output pairs.\n", "3. **Test the model**: Load the fine-tuned model and test its grammar correction capabilities."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Import Required Libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import pandas as pd\n", "from transformers import T5Tokenizer, T5ForConditionalGeneration\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Load the Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define TFRecord parsing logic\n", "feature_description = {\n", "    'input_text': tf.io.FixedLenFeature([], tf.string),\n", "    'target_text': tf.io.FixedLenFeature([], tf.string),\n", "}\n\n", "def parse_tfrecord(example_proto):\n", "    return tf.io.parse_single_example(example_proto, feature_description)\n\n", "# Load and parse dataset\n", "dataset_path = '../data/grammar_dataset.tfrecord'  # Update this path as necessary\n", "raw_dataset = tf.data.TFRecordDataset(dataset_path)\n", "parsed_dataset = raw_dataset.map(parse_tfrecord)\n\n", "# Display a few examples\n", "inputs, targets = [], []\n", "for record in parsed_dataset.take(5):\n", "    inputs.append(record['input_text'].numpy().decode('utf-8'))\n", "    targets.append(record['target_text'].numpy().decode('utf-8'))\n\n", "pd.DataFrame({'Input Text': inputs, 'Target Text': targets})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Tokenization Example"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the tokenizer\n", "tokenizer = T5Tokenizer.from_pretrained('google/t5-base')\n\n", "# Tokenize one example\n", "example_input = f\"grammar correction: {inputs[0]}\"\n", "tokenized = tokenizer(example_input, max_length=128, padding='max_length', truncation=True)\n\n", "# Display tokenized input\n", "print(\"Tokenized Input IDs:\", tokenized['input_ids'])\n", "print(\"Decoded Tokens:\", tokenizer.decode(tokenized['input_ids']))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Load and Test the Fine-Tuned Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load fine-tuned model\n", "model_path = '../models/fine_tuned_t5_base'  # Update this path as necessary\n", "model = T5ForConditionalGeneration.from_pretrained(model_path)\n", "tokenizer = T5Tokenizer.from_pretrained(model_path)\n\n", "# Test the model on a sample sentence\n", "test_sentence = \"She go to market every day.\"\n", "input_text = f\"grammar correction: {test_sentence}\"\n", "inputs = tokenizer.encode(input_text, return_tensors='pt', max_length=128, truncation=True)\n", "\n", "# Generate corrected text\n", "outputs = model.generate(inputs, max_length=128, num_beams=5, early_stopping=True)\n", "corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n", "print(\"Original Sentence:\", test_sentence)\n", "print(\"Corrected Sentence:\", corrected_sentence)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Visualize Training Data Distribution (Optional)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Analyze length of input sentences\n", "input_lengths = [len(text.split()) for text in inputs]\n\n", "# Plot histogram\n", "plt.hist(input_lengths, bins=20, color='blue', edgecolor='black')\n", "plt.title('Distribution of Sentence Lengths')\n", "plt.xlabel('Number of Words')\n", "plt.ylabel('Frequency')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}